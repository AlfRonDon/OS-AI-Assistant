# Auto-generated by Codex agent on 2025-12-01T00:27:00Z
#!/usr/bin/env python3
"""Aggregate quantization bench outputs into a summary CSV."""

import argparse
import csv
import json
import statistics
from pathlib import Path
from typing import Iterable, List


def load_runs(results_dir: Path) -> List[dict]:
    runs: List[dict] = []
    if not results_dir.exists():
        return runs
    for path in results_dir.glob("*.json"):
        try:
            data = json.load(path.open("r", encoding="utf-8"))
        except Exception:
            continue
        if isinstance(data, dict):
            data = [data]
        for item in data:
            item = dict(item)
            item.setdefault("variant", path.stem.split("_")[0])
            runs.append(item)
    return runs


def _safe_mean(values: Iterable[float | None]) -> float | None:
    nums = [v for v in values if isinstance(v, (int, float))]
    if not nums:
        return None
    return float(statistics.fmean(nums))


def aggregate(runs: List[dict]) -> List[dict]:
    grouped = {}
    for run in runs:
        key = (run.get("variant"), run.get("batch_size"))
        grouped.setdefault(key, []).append(run)

    summary: List[dict] = []
    for (variant, batch_size), items in grouped.items():
        summary.append(
            {
                "variant": variant,
                "batch_size": batch_size,
                "runs": len(items),
                "p50_ms_avg": _safe_mean(item.get("p50_ms") for item in items),
                "p95_ms_avg": _safe_mean(item.get("p95_ms") for item in items),
                "peak_rss_mb_avg": _safe_mean(item.get("peak_rss_mb") for item in items),
                "load_time_ms_avg": _safe_mean(item.get("load_time_ms") for item in items),
                "obedience_pass_rate_avg": _safe_mean(item.get("obedience_pass_rate") for item in items),
                "tokens_per_sec_avg": _safe_mean(item.get("tokens_per_sec") for item in items),
            }
        )
    return summary


def write_csv(summary: List[dict], output_csv: Path) -> None:
    output_csv.parent.mkdir(parents=True, exist_ok=True)
    fieldnames = [
        "variant",
        "batch_size",
        "runs",
        "p50_ms_avg",
        "p95_ms_avg",
        "peak_rss_mb_avg",
        "load_time_ms_avg",
        "obedience_pass_rate_avg",
        "tokens_per_sec_avg",
    ]
    with output_csv.open("w", newline="", encoding="utf-8") as fh:
        writer = csv.DictWriter(fh, fieldnames=fieldnames)
        writer.writeheader()
        for row in summary:
            writer.writerow(row)


def main() -> int:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--results-dir", default="quant_tuning/results", type=Path)
    parser.add_argument("--output-csv", default="quant_tuning/summary.csv", type=Path)
    args = parser.parse_args()

    runs = load_runs(args.results_dir)
    summary = aggregate(runs)
    write_csv(summary, args.output_csv)
    print(f"[quant] wrote summary to {args.output_csv} (groups={len(summary)})")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
