#!/usr/bin/env bash
# Auto-generated by Codex agent on 2025-12-01T00:27:00Z
set -euo pipefail

REPO_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
RESULTS_DIR="${REPO_ROOT}/quant_tuning/results"
mkdir -p "${RESULTS_DIR}"

VARIANTS=${VARIANTS:-"q4_0 q4_K_M q4_KV q8_0 q8_0-kv-hybrid"}
BATCH_SIZES=${BATCH_SIZES:-"1 4 8"}
WARMUPS=${WARMUPS:-3}
RUNS=${RUNS:-20}
DATE_TAG=${DATE_TAG:-"$(date +%Y%m%d)"}
MODEL_PREFIX="${REPO_ROOT}/models/gpt-oss-20b"

echo "[quant] repo=${REPO_ROOT}"
echo "[quant] variants=${VARIANTS}"
echo "[quant] batch_sizes=${BATCH_SIZES}"
echo "[quant] warmups=${WARMUPS} runs=${RUNS}"

for variant in ${VARIANTS}; do
  MODEL_PATH="${MODEL_PREFIX}-${variant}.gguf"
  if [[ ! -f "${MODEL_PATH}" ]]; then
    echo "[quant] skip ${variant} (missing ${MODEL_PATH})"
    continue
  fi

  OUT_PATH="${RESULTS_DIR}/${variant}_${DATE_TAG}.json"
  for batch_size in ${BATCH_SIZES}; do
    echo "[quant] running variant=${variant} batch_size=${batch_size}"
    START_MS=$(python - <<'PY'
import time
print(int(time.time() * 1000))
PY
)
    python "${REPO_ROOT}/bench/benchmark_model.py" --model-path "${MODEL_PATH}" --warmups "${WARMUPS}" --runs "${RUNS}"
    END_MS=$(python - <<'PY'
import time
print(int(time.time() * 1000))
PY
)
    ELAPSED_MS=$((END_MS - START_MS))

    python - <<PY
import json
import pathlib
from datetime import datetime

repo = pathlib.Path("${REPO_ROOT}")
bench_path = repo / "bench" / "bench_results.json"
target = pathlib.Path("${OUT_PATH}")
batch_size = int("${batch_size}")
variant = "${variant}"
elapsed_ms = int(${ELAPSED_MS})
now = datetime.utcnow().isoformat() + "Z"

try:
    data = json.load(open(bench_path, "r", encoding="utf-8"))
except FileNotFoundError:
    raise SystemExit(f"bench results missing at {bench_path}")

entry = {
    "timestamp": now,
    "variant": variant,
    "batch_size": batch_size,
    "runs": data.get("runs"),
    "warmups": data.get("warmups"),
    "model_path": data.get("model_path"),
    "p50_ms": data.get("latencies_ms", {}).get("p50"),
    "p95_ms": data.get("latencies_ms", {}).get("p95"),
    "peak_rss_mb": (data.get("peak_rss") or 0) / (1024 * 1024),
    "load_time_ms": elapsed_ms,
    "obedience_pass_rate": data.get("obedience_pass_rate"),
    "tokens_per_sec": data.get("tokens_per_sec"),
}

existing = []
if target.exists():
    with target.open("r", encoding="utf-8") as fh:
        try:
            existing = json.load(fh)
            if not isinstance(existing, list):
                existing = [existing]
        except json.JSONDecodeError:
            existing = []

existing.append(entry)
with target.open("w", encoding="utf-8") as fh:
    json.dump(existing, fh, indent=2)

print(f"[quant] wrote {target} (entries={len(existing)})")
PY
  done
done
