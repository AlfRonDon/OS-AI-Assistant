{
    "fetch":  true,
    "files_fetched":  [
                          "config.json",
                          "tokenizer.json",
                          "tokenizer_config.json"
                      ],
    "conversion_success":  false,
    "convert_log":  "reports/convert_conversion_retry.log",
    "check_output_path":  "reports/check_model_load_output.json",
    "recommendations":  [
                            "Install or expose llama_cpp.convert_hf_to_gguf or use scripts/convert_hf_to_gguf.py with full dependencies (torch, gguf extras) to produce gguf.",
                            "Once a gguf is produced, rerun python scripts/check_model_load.py to validate load and proceed with bench/obedience tests if RSS allows."
                        ]
}
